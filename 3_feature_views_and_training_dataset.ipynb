{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb83ff8",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Data & Feature views</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This is the second part of the quick start series of tutorials about Hopsworks Feature Store. This notebook explains how to read from a feature group and create training dataset within the feature store</span>\n",
    "\n",
    "## üóíÔ∏è In this notebook we will see how to create a training dataset from the feature groups: \n",
    "\n",
    "1. Retrieving Feature Groups.\n",
    "2. Defining Transformation functions.\n",
    "4. Feature View creation.\n",
    "5. Training Dataset with training, validation and test data.\n",
    "\n",
    "![part2](images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b3bcd1",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ad779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/167\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eaa049",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™Ñ Retrieving Feature Groups</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735a083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name = 'air_quality_fg',\n",
    "    version = 1\n",
    ")\n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name = 'weather_fg',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be427dca",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üíº Query Preparation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc3192d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-12 15:21:44,470 INFO: USE `maksym00_featurestore`\n",
      "2022-09-12 15:21:45,676 INFO: WITH right_fg0 AS (SELECT *\n",
      "FROM (SELECT `fg1`.`city` `city`, `fg1`.`aqi` `aqi`, `fg1`.`date` `date`, `fg1`.`iaqi_h` `iaqi_h`, `fg1`.`iaqi_p` `iaqi_p`, `fg1`.`iaqi_pm10` `iaqi_pm10`, `fg1`.`iaqi_t` `iaqi_t`, `fg1`.`o3_avg` `o3_avg`, `fg1`.`o3_max` `o3_max`, `fg1`.`o3_min` `o3_min`, `fg1`.`pm10_avg` `pm10_avg`, `fg1`.`pm10_max` `pm10_max`, `fg1`.`pm10_min` `pm10_min`, `fg1`.`pm25_avg` `pm25_avg`, `fg1`.`pm25_max` `pm25_max`, `fg1`.`pm25_min` `pm25_min`, `fg1`.`uvi_avg` `uvi_avg`, `fg1`.`uvi_max` `uvi_max`, `fg1`.`uvi_min` `uvi_min`, `fg1`.`city` `join_pk_city`, `fg1`.`date` `join_pk_date`, `fg1`.`date` `join_evt_date`, `fg0`.`tempmax` `tempmax`, `fg0`.`tempmin` `tempmin`, `fg0`.`temp` `temp`, `fg0`.`feelslikemax` `feelslikemax`, `fg0`.`feelslikemin` `feelslikemin`, `fg0`.`feelslike` `feelslike`, `fg0`.`dew` `dew`, `fg0`.`humidity` `humidity`, `fg0`.`precip` `precip`, `fg0`.`precipprob` `precipprob`, `fg0`.`precipcover` `precipcover`, `fg0`.`snow` `snow`, `fg0`.`snowdepth` `snowdepth`, `fg0`.`windgust` `windgust`, `fg0`.`windspeed` `windspeed`, `fg0`.`winddir` `winddir`, `fg0`.`pressure` `pressure`, `fg0`.`cloudcover` `cloudcover`, `fg0`.`visibility` `visibility`, `fg0`.`solarradiation` `solarradiation`, `fg0`.`solarenergy` `solarenergy`, `fg0`.`uvindex` `uvindex`, `fg0`.`conditions` `conditions`, RANK() OVER (PARTITION BY `fg0`.`city`, `fg0`.`date`, `fg1`.`date` ORDER BY `fg0`.`date` DESC) pit_rank_hopsworks\n",
      "FROM `maksym00_featurestore`.`air_quality_fg_1` `fg1`\n",
      "INNER JOIN `maksym00_featurestore`.`weather_fg_1` `fg0` ON `fg1`.`city` = `fg0`.`city` AND `fg1`.`date` = `fg0`.`date` AND `fg1`.`date` >= `fg0`.`date`) NA\n",
      "WHERE `pit_rank_hopsworks` = 1) (SELECT `right_fg0`.`city` `city`, `right_fg0`.`aqi` `aqi`, `right_fg0`.`date` `date`, `right_fg0`.`iaqi_h` `iaqi_h`, `right_fg0`.`iaqi_p` `iaqi_p`, `right_fg0`.`iaqi_pm10` `iaqi_pm10`, `right_fg0`.`iaqi_t` `iaqi_t`, `right_fg0`.`o3_avg` `o3_avg`, `right_fg0`.`o3_max` `o3_max`, `right_fg0`.`o3_min` `o3_min`, `right_fg0`.`pm10_avg` `pm10_avg`, `right_fg0`.`pm10_max` `pm10_max`, `right_fg0`.`pm10_min` `pm10_min`, `right_fg0`.`pm25_avg` `pm25_avg`, `right_fg0`.`pm25_max` `pm25_max`, `right_fg0`.`pm25_min` `pm25_min`, `right_fg0`.`uvi_avg` `uvi_avg`, `right_fg0`.`uvi_max` `uvi_max`, `right_fg0`.`uvi_min` `uvi_min`, `right_fg0`.`tempmax` `tempmax`, `right_fg0`.`tempmin` `tempmin`, `right_fg0`.`temp` `temp`, `right_fg0`.`feelslikemax` `feelslikemax`, `right_fg0`.`feelslikemin` `feelslikemin`, `right_fg0`.`feelslike` `feelslike`, `right_fg0`.`dew` `dew`, `right_fg0`.`humidity` `humidity`, `right_fg0`.`precip` `precip`, `right_fg0`.`precipprob` `precipprob`, `right_fg0`.`precipcover` `precipcover`, `right_fg0`.`snow` `snow`, `right_fg0`.`snowdepth` `snowdepth`, `right_fg0`.`windgust` `windgust`, `right_fg0`.`windspeed` `windspeed`, `right_fg0`.`winddir` `winddir`, `right_fg0`.`pressure` `pressure`, `right_fg0`.`cloudcover` `cloudcover`, `right_fg0`.`visibility` `visibility`, `right_fg0`.`solarradiation` `solarradiation`, `right_fg0`.`solarenergy` `solarenergy`, `right_fg0`.`uvindex` `uvindex`, `right_fg0`.`conditions` `conditions`\n",
      "FROM right_fg0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>aqi</th>\n",
       "      <th>date</th>\n",
       "      <th>iaqi_h</th>\n",
       "      <th>iaqi_p</th>\n",
       "      <th>iaqi_pm10</th>\n",
       "      <th>iaqi_t</th>\n",
       "      <th>o3_avg</th>\n",
       "      <th>o3_max</th>\n",
       "      <th>o3_min</th>\n",
       "      <th>...</th>\n",
       "      <th>windgust</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>winddir</th>\n",
       "      <th>pressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kyiv</td>\n",
       "      <td>2</td>\n",
       "      <td>1662670800000</td>\n",
       "      <td>99.90</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>36.4</td>\n",
       "      <td>14.8</td>\n",
       "      <td>87.8</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>71.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>146.3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kyiv</td>\n",
       "      <td>4</td>\n",
       "      <td>1662584400000</td>\n",
       "      <td>99.90</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>2</td>\n",
       "      <td>12.45</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>24.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>48.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>217.9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kyiv</td>\n",
       "      <td>2</td>\n",
       "      <td>1662498000000</td>\n",
       "      <td>65.58</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.02</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>24.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>1022.3</td>\n",
       "      <td>34.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>227.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kyiv</td>\n",
       "      <td>6</td>\n",
       "      <td>1662411600000</td>\n",
       "      <td>98.78</td>\n",
       "      <td>1022.7</td>\n",
       "      <td>2</td>\n",
       "      <td>13.91</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>24.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>267.0</td>\n",
       "      <td>1022.3</td>\n",
       "      <td>34.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>227.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malmo</td>\n",
       "      <td>23</td>\n",
       "      <td>1662670800000</td>\n",
       "      <td>86.00</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>7</td>\n",
       "      <td>12.70</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>46.1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1010.3</td>\n",
       "      <td>87.1</td>\n",
       "      <td>17.1</td>\n",
       "      <td>171.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Rain, Partially cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    city  aqi           date  iaqi_h  iaqi_p  iaqi_pm10  iaqi_t  o3_avg  \\\n",
       "0   Kyiv    2  1662670800000   99.90  1021.3          1   10.00      20   \n",
       "1   Kyiv    4  1662584400000   99.90  1017.6          2   12.45      22   \n",
       "2   Kyiv    2  1662498000000   65.58  1020.0          1   21.02      22   \n",
       "3   Kyiv    6  1662411600000   98.78  1022.7          2   13.91      19   \n",
       "4  Malmo   23  1662670800000   86.00  1006.3          7   12.70      33   \n",
       "\n",
       "   o3_max  o3_min  ...  windgust  windspeed  winddir  pressure  cloudcover  \\\n",
       "0      33       6  ...      36.4       14.8     87.8    1022.5        71.8   \n",
       "1      32      10  ...      24.8        9.7    132.9    1019.4        48.4   \n",
       "2      32      10  ...      24.5        9.7    267.0    1022.3        34.8   \n",
       "3      27      11  ...      24.5        9.7    267.0    1022.3        34.8   \n",
       "4      35      32  ...      46.1       28.0    127.0    1010.3        87.1   \n",
       "\n",
       "   visibility  solarradiation  solarenergy  uvindex              conditions  \n",
       "0        24.1           146.3         12.6      5.0  Rain, Partially cloudy  \n",
       "1        24.1           217.9         18.7      7.0        Partially cloudy  \n",
       "2        24.1           227.5         19.6      7.0        Partially cloudy  \n",
       "3        24.1           227.5         19.6      7.0        Partially cloudy  \n",
       "4        17.1           171.3         14.8      6.0  Rain, Partially cloudy  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = air_quality_fg.select_all().join(weather_fg.select_all())\n",
    "\n",
    "query_show = query.show(5)\n",
    "col_names = query_show.columns\n",
    "\n",
    "query_show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff1e11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\">üßëüèª‚Äçüî¨ Transformation functions</span>\n",
    "\n",
    "Hopsworks Feature Store provides functionality to attach transformation functions to training datasets.\n",
    "\n",
    "Hopsworks Feature Store also comes with built-in transformation functions such as `min_max_scaler`, `standard_scaler`, `robust_scaler` and `label_encoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423c4293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['min_max_scaler', 'robust_scaler', 'standard_scaler', 'label_encoder']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t_func.name for t_func in fs.get_transformation_functions()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28563812",
   "metadata": {},
   "source": [
    "We can retrieve transformation function we need .\n",
    "\n",
    "To attach transformation function to training dataset provide transformation functions as dict, where key is feature name and value is online transformation function name.\n",
    "\n",
    "Also training dataset must be created from the Query object. Once attached transformation function will be applied on whenever save, insert and get_serving_vector methods are called on training dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad29953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformation functions.\n",
    "standard_scaler = fs.get_transformation_function(name = 'standard_scaler')\n",
    "label_encoder = fs.get_transformation_function(name = 'label_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aad7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = ['city','date','conditions']\n",
    "\n",
    "mapping_transformers = {col_name:standard_scaler for col_name in col_names if col_name not in category_cols}\n",
    "category_cols = {col_name:label_encoder for col_name in category_cols if col_name != 'date'}\n",
    "\n",
    "mapping_transformers.update(category_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83a1681",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.create_feature_view()` method.\n",
    "\n",
    "We can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "403df0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/167/fs/109/fv/air_quality_fv/version/1\n"
     ]
    }
   ],
   "source": [
    "feature_view = fs.create_feature_view(\n",
    "    name = 'air_quality_fv',\n",
    "    version = 1,\n",
    "    transformation_functions = mapping_transformers,\n",
    "    query = query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c723c54",
   "metadata": {},
   "source": [
    "For now `Feature View` is saved in Hopsworks and we can retrieve it using `FeatureStore.get_feature_view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721c4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name = 'air_quality_fv',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1187a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "To create training dataset we use `FeatureView.create_training_data()` method.\n",
    "\n",
    "Here are some importand things:\n",
    "\n",
    "- It will inherit the name of FeatureView.\n",
    "\n",
    "- The feature store currently supports the following data formats for\n",
    "training datasets: **tfrecord, csv, tsv, parquet, avro, orc**.\n",
    "\n",
    "- We can choose necessary format using **data_format** parameter.\n",
    "\n",
    "- **start_time** and **end_time** in order to filter dataset in specific time range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3e7b2",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Dataset with train, validation and test splits</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299bd245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/167/jobs/named/air_quality_fv_1_1_create_fv_td_12092022122417/executions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `1`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, <hsfs.core.job.Job at 0x7fc9469a46d0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_view.create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51507c0",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> Next Steps</span>\n",
    "\n",
    "In the next notebook, we will train a model on the Training Dataset we created in this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
